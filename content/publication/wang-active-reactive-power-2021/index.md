---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Active and Reactive Power Coordinated Control of Active Distribution Networks
  Based on Prioritized Reinforcement Learning
subtitle: ''
summary: ''
authors:
- Xinming Wang
- admim
- Xin Cao
- Wenchuan Wu
- Shihui Li
- Xiaobu Jia
tags:
- active and reactive power coordination
- Biological system modeling
- Energy resources
- Green products
- Numerical simulation
- Power control
- prioritized experience replay
- Reactive power
- reinforcement learning
- Reinforcement learning
- Renewable energy sources
categories: []
date: '2020-03-10T11:04:01.029334Z'
lastmod: 2022-03-10T19:04:01+08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-03-10T11:04:01.029334Z'
publication_types:
- '1'
abstract: With the increasing penetration of renewable energy, voltage violation and
  network loss problems have hindered the secure and efficient operation of active
  distribution networks (ADN). Therefore, properly utilizing the reactive power of
  the inverter-based energy resources is inevitable. However, in the ADNs, active
  and reactive power (P&Q) are coupled both in the capacity and in the power flow.
  Moreover, the models of complicated ADNs are hard to maintain since the operation
  budget is limited and environment varies all the time. Hence, we develop an active
  and reactive power coordinated control of ADNs based on reinforcement learning (RL),
  which learns the control policy from interactions between the controller and the
  ADN. Since the RL-based method is designed for online application, our proposed
  method utilizes prioritized experience replay to promote efficiency and optimality.
  Comparing with traditional P&Q coordinated control methods, our method does not
  require the accurate model of ADN, but can achieve near-optimal state with high
  sample efficiency. Numerical simulations not only demonstrate the superiority on
  eliminating voltage violation, reducing network loss and maximizing the system economy,
  but also show the improvement of our proposed method comparing with existing RL-based
  methods.
publication: '*2021 Power System and Green Energy Conference (PSGEC)*'
doi: 10.1109/PSGEC51302.2021.9541702
---
